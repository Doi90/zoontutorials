---
title: "Data exploration and processing"
output:
  html_document:
    css: zoon.css
    toc: yes
    toc_float:
      collapsed: false
      toc_depth: 4
    theme: lumen
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteIndexEntry{Exploring Your Data}
  %\VignetteEncoding{UTF-8}
---

```{r eval=TRUE, echo=FALSE, warning=FALSE, message=FALSE}
# set up knitr options
knitr::opts_chunk$set(message = FALSE,
               warning = FALSE,
               fig.align = 'center',
               dev = c('png'),
               cache = TRUE)
```

<hr>

# Introduction

When we undertake a Species Distribution Model (SDM) we use both species occurrence data, records collected from field surveys or collated observations, as well as environmental predictor data. Before beginning to use covariate data to model occurrence over space, a crucial first step is to familiarise ourselves with the data and its limitations. It is important to do this before modelling the data, as data exploration can result in consequences for the choice of model applied as well as the accurracy of the inference taken from the model.  

There are some generally agreed upon guidelines for this data exploration and processing, but it is also highly subjective and open to interpretation. This guide suggests the following steps (Figure 1). In this guide we present resources in both base R as well as using `zoon` `output` and `process` modules within the `workflow()` to go through the following key steps. 

```{r echo = F, out.width= '650px', fig.align = "center", fig.cap="*Figure 1. Conceptual flowchart for data exploration steps.*"}
knitr::include_graphics("../vignettes/Images/DataExp_ConceptualDiagram.png")
```

We will start by setting up a basic `zoon` `workflow()` with the Carolina wren presence-only data and raster covariate datasets for illustration.  We will set `process = Background(1000)`, `model = NullModel`, and `output = PrintMap` - this map simply shows us our raw occurrence points (in red) and our background points (in black), no model has been applied. 

```{r packages, message = FALSE, warning = FALSE}
library(zoon)
```

```{r workflow, message = FALSE, warning = FALSE}
Carolina_Wren_Workflow <- workflow(occurrence = CarolinaWrenPO,
                                   covariate = CarolinaWrenRasters,
                                   process = Background(1000),
                                   model = NullModel,
                                   output = PrintMap)
```

# Data exploration

It is helpful to have a basic workflow loaded before we begin so that we can take advantage of zoon's accessor functions. We can call accessor function `Process` to generate a data frame object with extracted raster covariate values for each respective occurrence point. We can examine the first six rows of this data frame by using the base R function `head()`. 

``` {r}
occ.cov.df <- Process(Carolina_Wren_Workflow)$df
head(occ.cov.df)
```

It is useful to begin by checking the format of the covariates included. Categorical variables should be stored as factors, however they may be listed, for example, in a numerical index (e.g. vegetation categories identified as 1-10 instead of 'VegClass1', 'VegClass2', etc) and therefore interpreted as numerical data. Similarly, if there are any typos in numerical data entries that introduce characters (e.g. '2 cm' instead of '2'), then a continuous variable will be classed as a factor. We can check the format of the data with the `str()` function, or check individual variables with `class()`. 

``` {r}
str(occ.cov.df)
class(occ.cov.df$pcMix)
```

<hr>

# Data cleaning/outliers

Species distribution datasets are, to varying degrees, reliant on manually-compiled data from observations. Even in situations where we are fitting a model to entirely remotely-sensed data such as bioclimatic variables, our species occurrence records are usually pen-and-paper recordings from the field. This manual data entry can lead to mistakes.

Inaccurate data can lead us to draw false conclusions, and for conservation work this could mean squandering our limited resources for a species in locations where the species is not likely to occur. For example, maybe the maximum value in your elevation variable is 1000 m, but you know that the highest peak in your study region is only 500 m. During the data entry process someone may have added an extra 0 to a 100 m measurement by mistake. Maybe your vegetation classification is showing as having ten levels despite it being an eight-category scale. Chances are a spelling mistake as benign as 'forest' instead of 'Forest' is the culprit. 

```{r}
summary(occ.cov.df$pcGr)
max(occ.cov.df$pcGr)
min(occ.cov.df$pcGr)
```

NA values are to be expected in our raster data (unless they are oblong in shape) as they are commonly masked to cover only a particular region (e.g. the border of a country or a national park) but are stored as a matrix and thus padded with NA values in cells of no interest, but we would not expect NA values in our training data. Finding NA values for covariates in the training data could also indicate that some data points have incorrect latitude/longitude values and are being mapped to locations outide the extent of our study, or that the data point sits on the border of the study region and "misses" the raster due to its resolution (i.e. a diagonal line is instead a series of alternating horizontal and vertical lines) and should be adjusted slightly.

If you've identified errors in your occurrence data, one of the `zoon` modules, `Clean`, removes impossible, incomplete, or unlikely species occurrence points. Impossible occurrence points include those where the location doesn't exist, incomplete records may be missing either a longitude or latitude value (or both), and unlikely data points are those that fall well outside the geographic range of your study area (for example, in the middle of the sea). Within `Clean` these options are referred to by number as impossible (1), incomplete (2), and unlikely (3), and this module is used as follows:

```{r Clean, eval=FALSE}
process = Clean(which = c(1,2,3))
```

<hr>

# Collinearity

Correlated data and masking effects. 
do not necessarily have to remove correlated variables. but need to cnsider how including both will affect inference of the data. 

pairplot. 
+  Two or more of our covariates are correlated. In this situation we cannot accurately discern the difference in species response to these covariates, and such we should choose one or more of these covariates to remove from our analysis (based on ecological reasoning) **what else?**

+  Our training data does not adequately represent the full range of our covariate data in the study region. For example, we have an elevation covariate ranging from 0-100 m, but our samples are all from the 0-50 m range. This means that our predictions will have to extrapolate outside the sample range, and we then have to assume that the estimated relationship between species occurrence and the covariate holds under these conditions.

Categorical data distribution

<hr>

# Standardising variables

A common transformation, so common in fact that it is standard practice for most analyses nowadays and not really thought of in the same vein as transformation anymore, is the standarisation of variables. While it can improve the efficiency of model fitting algorithms, the main benefit of this transformation allows us to directly compare the influence of different variables on species distributions by placing them on the same scale. For example, the regression coefficient for the distance of a site to roads might be +3.0 when measured in kilometres, but +0.003 if measured in meters, and the effect of average temperature in Celsius could be -10. How would we compare the effect of these variables?

We do this with the `StandardiseCov` module in `zoon` to standardise covariates in the model. By default, the module standardises all variables by subtracting their mean and dividing by their standard deviation, also known as a 'z-score'. This standardisation places variables on the same scale, allowing us to compare the relative effects of different covariates within a model. To use this module we need to choose which variables to exclude from standardisation (if any), and whether to use the Gelman variant (standardises by two standard deviations instead of one - **(link to this here)**). 

Some examples of how to use the module are below. The first is the default fit of the module that performs normal standardisation on all variables. The second calculates the Gelamn variant of standardisation on all variables except "VarB" and "VarC".

```{r StandardiseCov, eval=FALSE}
process = StandardiseCov() # default form

process = StandardiseCov(Gelman = TRUE,
                         exclude = c("VarB", "VarC"))
```

<hr>

# Data transformation

(check model assumptions -- for cetain model types, or where biolgoically relevant.)

Data transformation is achieved in `zoon` using the `Transform` module. To use this module we need to define the transformation, nominate the variable to be transformed, and whether to replace the original variable or create a new one. We define the transformation in a similar manner to defining a function in base R. This takes the format of setting the `trans` argument in this module to the format of `function(x) {our transformation}`. We select the variables we want to apply this transformation to by supplying a character vector to the `which_cov` argument, and choose to replace the original variable or not by setting the `replace` argument to `TRUE` or `FALSE`.

Sometimes the relationship between our response variable and predictor variable is not adequately represented using a standard linear relationship. For example, the probability of species occurrence might increase with elevation, but beyond a certain point it starts to decrease again. Polynomial terms are used to capture these relationships.

Now, it may not be intuitive to think of polynomial terms as interactions, but the structure of defining interactions in the manner of the `addInteraction` module also suits defining polynomial terms. Rather than using characters vectors of multiple variables like defining interactions, we define a character vector of repeated instances of the same variable name of a length equal to the order of polynomial term we want to define. For example:

While polynomial terms let us represent non-linear relationships between the response and predictor variables, we have to be careful in our application of them. Polynomial terms add extra parameters in the model to be estimated, and we need to be careful that we don't overload the model with additional terms unless we have enough data to be confident in estimating that many terms **(rule of thumb being 1 parameter for every 10 observations, or every 10 presences? I've heard different from different sources)**. To this end we should only apply polynomial terms to predictor variables where it is ecologically defensible. Variables like elevation, temperature, and rainfall where we could expect there to be a "sweet spot" for species occurrence, such that probability of occurrence would decrease outside of a certain variable range, would be suitable candidates for polynomial terms. Variables where we might expect a linear response for species occurrence include distance-based ones such as distance to roads, disturbances, or food/water resources. Categorical variables are another one where we would not use polynomial terms.


Let's run through a couple of examples. If we want to square a variable called VarA and save it as an additional variable in our dataset (i.e. do not replace original variable) we would use this:

```{r eval=FALSE}
process = Transform(trans = function(x) {x^2},
                    which_cov = "VarA",
                    replace = FALSE)
```

If we want to perform a log transformation to the variables VarA, VarB, and VarC, and replace the original variables in the dataset with our newly transformed variables, we would use this:

```{r eval=FALSE}
process = Transform(trans = function(x) {log(x)},
                    which_cov = c("VarA", "VarB", "VarC"),
                    replace = TRUE)
```

If we want to get fancy and provide different transformations to different variables we can achieve this using the `Chain()` function:

```{r eval=FALSE}
process = Chain(Transform(trans = function(x) {x^2},
                          which_cov = c("VarA", "VarB"),
                          replace = FALSE),
                Transform(trans = function(x) {log(x)},
                          which_cov = c("VarC", "VarD")))
```

<hr>

# Relationships
A starting step in your analysis might be to explore how the univariate relationships

<hr>

# Interactions

Typical inference assumes that unique predictor variables have an independent effect on our response variable (species occurrence). This makes sense in many cases, where we are trying to 

The `addInteraction` module in `zoon` lets us define the interactions between variables in the model. There are multiple ways to implement this module: adding all pairwise interactions, defining set interactions between a select group of variables, and specifying polynomial terms.

A pairwise interaction is the interaction between two variables in a model such that:

$Y = b_0 + b_1*X_1 + b_2*X_2 + b_3(X_1*X_2)$

where b3 is the interaction term between the variables X1 and X2. 

To implement all possible pairwise interactions in the model we write up the module like this:

```{r Interaction_AllPairs, eval=FALSE}
process = addInteraction(which.covs = 'pairs')
```

Rather than a blanket application of interaction terms across our model, we might decide that it is more ecologically reasonable to define interactions only between a select group of variables. For example, we might not expect to see an interaction between average rainfall and distance to roads, but to see one between elevation and percentage forest cover. There are multiple ways to achieve this so lets go through them one at a time:

+  To define the pairwise interaction between any two variables as a character vector:

```{r Interaction_Pair, eval=FALSE}
process = addInteraction(which.covs = c("A","B"))   # adds an interaction between A & B
```

+  To define multiple pairwise interactions, but not *all* pairwise interactions, we make use of `R`'s `list()` function. We provide a list of interaction terms as character vectors like so:

```{r Interaction_MultPairs, eval=FALSE}
process = addInteraction(which.covs = list(c("A","B"), c("A","C")))   # adds interactions between A & B and A & C, but not B & C
```

+  To define higher order interactions between more than two variables we just need to extend the length of our character vectors. This will define the highest order interaction term between all of the selected variables as well as all combinations of lower-order interaction terms.

```{r Interaction_Three-way, eval=FALSE}
process = addInteraction(which.covs = c(A,B,C))   # adds all two-way (e.g. A & B) interactions and a three-way interaction between A, B & C
```

the addInteraction method can also be used as an alternative to coding in polynomial terms. 

```{r eval=FALSE}
process = addInteractions(which.covs = c(A,A))   # leads to a quadratic polynomial

process = addInteractions(which.covs = c(A,A,A))   # leads to a cubic, polynomial
```

<hr>

A tidy summary of many of the following data exploration methods is provided with the `GenerateCovariateReport` `Output` module. This is based on the `GenerateReport()` function in the `DataExplorer` `R` package, but tailored specifically for SDM analysis.

This module generates a data profiling report for our training data (the data set that our model is fit to) and/or our raster data (that our model uses to predict the distribution of our study species). These reports will show our data's structure, the percentage of missing data, the distribution of our covariates (histograms for continuous data, bar charts for discrete), and show the results of a correlation analysis. We need to tell the module which report(s) to generate by setting the `type` argument to one of "D" (Data Report only), "R" (Raster report only), or "DR" (Data and Raster Report).

```{r DataReport, eval=FALSE}
output = GenerateCovariateReport(type = "DR")
```



