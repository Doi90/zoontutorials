---
title: "Selecting and preparing covariates"
output:
  html_document:
    css: zoon.css
    toc: yes
    toc_float:
      collapsed: false
      toc_depth: 4
    theme: lumen
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteIndexEntry{Selecting and preparing covariates}
  %\VignetteEncoding{UTF-8}
---

```{r eval=TRUE, echo=FALSE, warning=FALSE, message=FALSE}
# set up knitr options
knitr::opts_chunk$set(message = FALSE,
               warning = FALSE,
               fig.align = 'center',
               dev = c('png'),
               cache = TRUE, 
               comment = '')
```

<hr>

## Introduction

When we undertake a Species Distribution Model (SDM) we use both species occurrence data collected from field surveys or collated observations as well as environmental predictor data. Before beginning to use covariate data to model occurrence over space, a crucial first step is to familiarise ourselves with the data and its limitations. It is important to do this before modelling the data, as data exploration can result in consequences for the choice of model applied as well as the accurracy of the inference taken from the model. Equally, choice of model a priori may bring a unique set of assumptions that we need to check for in our data. 

After exploring our data, we may want to implement various data processing steps into our `zoon` `workflow`. There are some generally agreed upon guidelines for this data exploration and processing, but it is also highly subjective and open to interpretation. This guide outlines a few suggested steps implemented in both base R as well as using `zoon` `output` and `process` modules for both the data exploration and processing steps (Figure 1).

<!-- ```{r echo = F, out.width= '400px', fig.align = "center", fig.cap="*Figure 1. Conceptual flowchart for process modules in covariates selection and reparation.*"} -->
<!-- knitr::include_graphics("../vignettes/Images/SelectCov_ConceptualDiagram.png") -->
<!-- ``` -->

We will start by setting up a basic `zoon` `workflow()` **use different example so it also has ones that need transformation** with the Carolina wren presence-only data and raster covariate datasets for illustration.  We will set `process = Background(1000)`, `model = NullModel`, and `output = PrintOccurrenceMap` - this map simply shows us our raw occurrence points (in red) and our background points (in black), no model has been applied. 

```{r packages, message = FALSE, warning = FALSE}
library(zoon)
```

```{r workflow, message = FALSE, warning = FALSE}
Carolina_Wren_Workflow <- workflow(occurrence = CarolinaWrenPO,
                                   covariate = CarolinaWrenRasters,
                                   process = Background(1000),
                                   model = NullModel,
                                   output = PrintOccurrenceMap)
```

<hr>

# Data cleaning

If you've identified errors in your occurrence data, one of the `zoon` modules, `Clean`, removes impossible, incomplete, or unlikely species occurrence points. Impossible occurrence points include those where the location doesn't exist, incomplete records may be missing either a longitude or latitude value (or both), and unlikely data points are those that fall well outside the geographic range of your study area (for example, in the middle of the sea). Within `Clean` these options are referred to by number as impossible (1), incomplete (2), and unlikely (3), and this module is used as follows:

```{r Clean, eval=FALSE}
process = Clean(which = c(1,2,3))
```

**DW to add to clean module so it prints to screen what it removed**

# Standardising variables

For some modelling methods, it is helpful to standardise variables, thereby putting them on the same scale. This is not necessary for Boosted Regression Trees and Random Forest models, for example, and so it's important to be clear on the guidelines and assumptions of our selected modelling method in advance. Standardisation is achieved by subtracting the mean for a covariate from each individual value so all covariates are centred on zero, or additionally by dividing by the standard deviation, which makes the standard deviation of each covariate equal to one (this is called the 'z-score'). One major reason to standardise covarites is to aid interpretation of our model results. Regression parameters of covariates on the same scale allowing us to compare the influence of different variables on species distributions. Without standardisation, the regression coefficient for the distance of a site to roads might be +0.003 if measured in meters and the effect of average temperature in Celsius could be -10. How would we compare these coefficients? 

In addition, standardisation of covariates can aid in model fitting. If regression coefficients will be too different between two covariates in a model, then the software will struggle to converge on parameter estimates for both terms. 

We can standardise covariates in `zoon` with the `StandardiseCov` process module. By default, the module standardises all variables by subtracting their mean and dividing by their standard deviation (calculating their 'z-score'). To use this module we need to choose which variables to exclude from standardisation (if any), and whether to use the Gelman variant (standardises by two standard deviations instead of one). Some examples of how to use the module are below:

```{r StandardiseCov, eval=FALSE}
process = StandardiseCov() # default form

process = StandardiseCov(Gelman = TRUE,
                         exclude = c("VarB", "VarC"))
```

<hr>

# Data transformation

Transformation of covariate data is a way to re-express dependent variables in a non-linear form. Generally, decisions about transformation are subjective, and depend upon the assumptions of our chosen model as well as the natural biological underpinnings of our parameters. A few key reasons to transform data:

+ Biological justification: Many biological parameters are more naturally understood on a particular scale, for example, many plant biometric variables are typically log-transformed because the data are naturally skewed, with only a few very large values. 

+ Skewed/systematically varying residuals: Transformation does not just change the distribution of the raw data, it also implies a relationship of the residuals. If there is a pattern among the residuals ('heterscedasticity') then transformation can be used to remove that pattern (ensuring 'homoscedasticity'), which is an assumption of some models. 

+ To linearise a relationship/simplify a model: If the relationship between a covariate and the response variable is non-linear, then you may need to add extra terms to the model, making it more complicated. Transformation to linearlise this relationship thus simplifies the model. 

+ To add flexibility: Polynomial transformation is useful for variables whose impact on occurrence is not linear. Some environmental variables, such as elevation, temperature, and rainfall, actually have a peak value for occurrence and would therefore be good candidates for polynomial transformation.

Great care must be taken when adding transformations to our data, and there are several good reasons not to do so, or to take caution in doing so: 

+ Can complicate a model: Polynomial terms in particular add complexity to a model, and should only be attempted when you have enough data to reliably estimate those additional parameters. 

+ Masking outliers: Without a biological justification for doing so, transforming data simply to hide the impact of outlying values hides valuable insight in our data.

There is a process module for data transformation in `zoon` called `Transform`. To use this module we need to define the transformation, nominate the variable to be transformed, and decide whether to replace the original variable or to create a new one. We define the transformation in a similar manner to defining a function in base R. This takes the format of setting the `trans` argument in this module to the format of `function(x) {our transformation}`. We select the variables to transform by supplying a character vector to the `which_cov` argument, and determine variables to replace by setting the `replace` argument to `TRUE` or `FALSE`.

Let's run through a couple of examples. If we want to square a variable called VarA and save it as an additional variable in our dataset (i.e. do not replace original variable) we would use this:

```{r eval=FALSE}
process = Transform(trans = function(x) {x^2},
                    which_cov = "VarA",
                    replace = FALSE)
```

If we want to perform a log transformation to the variables VarA, VarB, and VarC, and replace the original variables in the dataset with our newly transformed variables, we would use this:

```{r eval=FALSE}
process = Transform(trans = function(x) {log(x)},
                    which_cov = c("VarA", "VarB", "VarC"),
                    replace = TRUE)
```

If we want to get fancy and provide different transformations to different variables we can achieve this using the `Chain()` function:

```{r eval=FALSE}
process = Chain(Transform(trans = function(x) {x^2},
                          which_cov = c("VarA", "VarB"),
                          replace = FALSE),
                Transform(trans = function(x) {log(x)},
                          which_cov = c("VarC", "VarD")))
```

<hr>

# Interactions

Typical inference assumes that unique predictor variables have an independent effect on our response variable (species occurrence). This makes sense in many cases, when we are reasonably confortable with the biological justification. For example, it is reasonable and backed by experimental evidence, to suppose that mosquito populations are more common in humid regions. This would be an independent effect of humidity on mosquito occurrence. However, we need to consider the conditionality of this assumption. Occurrence data are conditional upon how they enter our dataset (is data collection biased by region where we expect mosquitos to occur?) It is possible that the relationship between mosquito occurrence and humidity is *conditional* on another environmental variable. In this example, perhaps temperature moderates this relationship. A pairwise interaction is the interaction between two variables in a model such that:

$Y = b_0 + b_1*X_1 + b_2*X_2 + b_3(X_1*X_2)$

and where b3 is the interaction term between the variables X1 and X2. One way to check for interaction effects is to produce a coplot. **Add coplot module**

Once we have decided to add an interaction effect into our model, we can select from three possible ways to implement it in our model: add all pairwise interactions, define set interactions between a select group of variables, or specify polynomial terms.

### Pairwise interactions

To implement all possible pairwise interactions in the model we write up the module with the `addInteraction` process module like this:

```{r Interaction_AllPairs, eval=FALSE}
process = addInteraction(which.covs = 'pairs')
```

### Set interactions

Rather than a blanket application of interaction terms across our model, we might decide that it is more ecologically reasonable to define interactions only between a select group of variables. There are multiple ways to achieve this so lets go through them one at a time:

+  To define the pairwise interaction between any two variables as a character vector:

```{r Interaction_Pair, eval=FALSE}
process = addInteraction(which.covs = c("A","B"))   # adds an interaction between A & B
```

+  To define multiple pairwise interactions, but not *all* pairwise interactions, we make use of `R`'s `list()` function. We provide a list of interaction terms as character vectors like so:

```{r Interaction_MultPairs, eval=FALSE}
process = addInteraction(which.covs = list(c("A","B"), c("A","C")))   # adds interactions between A & B and A & C, but not B & C
```

+  To define higher order interactions between more than two variables we just need to extend the length of our character vectors. This will define the highest order interaction term between all of the selected variables as well as all combinations of lower-order interaction terms.

```{r Interaction_Three-way, eval=FALSE}
process = addInteraction(which.covs = c(A,B,C))   # adds all two-way (e.g. A & B) interactions and a three-way interaction between A, B & C
```

### Interactions as polynomial terms
the addInteraction method can also be used as an alternative to coding in polynomial terms. 

```{r eval=FALSE}
process = addInteractions(which.covs = c(A,A))   # leads to a quadratic polynomial

process = addInteractions(which.covs = c(A,A,A))   # leads to a cubic, polynomial
```



