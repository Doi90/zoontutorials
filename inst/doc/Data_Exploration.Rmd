---
title: "Data exploration"
output:
  html_document:
    css: zoon.css
    toc: yes
    toc_float:
      collapsed: false
      toc_depth: 4
    theme: lumen
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteIndexEntry{Data exploration}
  %\VignetteEncoding{UTF-8}
---

```{r eval=TRUE, echo=FALSE, warning=FALSE, message=FALSE}
# set up knitr options
knitr::opts_chunk$set(message = FALSE,
               warning = FALSE,
               fig.align = 'center',
               dev = c('png'),
               cache = TRUE, 
               comment = '')
```

<hr>

## Introduction

When we perform a Species Distribution Model analysis (SDM) we use species occurrence data collected from both structured field surveys and/or collated observation records as well as environmental predictor data. Before beginning to use covariate data to model occurrence over space, a crucial first step is to familiarise ourselves with the data and its limitations. It is important to do this before modelling the data, as data exploration can result in consequences for the choice of modelling method applied as well as the accurracy of the inference taken from the model. Equally, the choice of model *a priori* may bring a unique set of assumptions that we need to check for in our data. This guide outlines a few suggested steps implemented in both base R as well as using `zoon`'s `output` and `process` modules for data exploration (Figure 1).

** NEED TO CHANGE IMAGE AFTER SPLITTING GUIDE IN TWO **

```{r echo = F, out.width= '400px', fig.align = "center", fig.cap="*Figure 1. Conceptual flowchart for data exploration*"}
knitr::include_graphics("../vignettes/Images/DataExp_ConceptualDiagram.png")
```

We will start by setting up a basic `zoon` `workflow()` with Carolina wren presence-only data and raster covariate datasets for illustration.  We generate 1000 background points, fit a null model, and use the `PrintOccurrenceMap` output module to plot a map visualising our raw occurrence points (in red) and our background points (in black). 

```{r packages, message = FALSE, warning = FALSE}
library(zoon)
```

```{r workflow, message = FALSE, warning = FALSE}
Carolina_Wren_Workflow <- workflow(occurrence = CarolinaWrenPO,
                                   covariate = CarolinaWrenRasters,
                                   process = Background(1000),
                                   model = NullModel,
                                   output = PrintOccurrenceMap)
```

<hr>

## Data exploration

A simple step for exploring your data is extracting a summary of it. Looking at things like the minimum/maximum values and the spread of your data are useful for identifying potential sampling biases in your data. The data is also potentially subject to error. For example, maybe the maximum value in your elevation variable is 1000 m, but you know that the highest peak in your study region is only 500 m. During the data entry process someone may have added an extra 0 to a 100m measurement by mistake. Maybe your vegetation classification is showing as having ten levels despite it being an eight-category scale. Chances are a spelling mistake as benign as 'forest' instead of 'Forest' is the culprit. 

NA values are to be expected in our raster data (unless they are oblong in shape) as they are commonly masked to cover only a particular region (e.g. the border of a country or a national park) but are stored as a matrix and thus padded with NA values in cells of no interest, but we would not expect NA values in our training data. Finding NA values for covariates in the training data could also indicate that some data points have incorrect latitude/longitude values and are being mapped to locations outide the extent of our study, or that the data point sits on the border of the study region and "misses" the raster due to its resolution (i.e. a diagonal line is instead a series of alternating horizontal and vertical lines) and should be adjusted slightly.

The `DataSummary` output module extracts these summaries separately for both the (non-background) model fitting data and the prediction data. Once again using the Carolina wren data, we fit a `workflow()` using the `DataSummary` module to explore our data.

```{r workflow2, message = FALSE, warning = FALSE}
Carolina_Wren_Workflow <- workflow(occurrence = CarolinaWrenPO,
                                   covariate = CarolinaWrenRasters,
                                   process = Background(1000),
                                   model = NullModel,
                                   output = DataSummary)
```

**EXPAND ON WHAT WE SEE ONCE THE UPDATED MODULE PULL REQUEST GOES THROUGH**

<hr>

## Outliers/data cleaning

Species distribution datasets are, to varying degrees, reliant on observation records gathered by humans and therefore subject to human error. Even in situations where we are fitting a model to entirely remotely-sensed data such as bioclimatic variables, our species occurrence records are usually pen-and-paper recordings from the field. This manual data entry can lead to mistakes. Inaccurate data can lead us to draw false conclusions, and for conservation work this could mean squandering our limited resources for a species in locations where the species is not likely to occur. One way to check for nonsense entries is to the plot occurrence data to covariate one by one, allowing you to isolate unusual entries. For example, if you plotted against latitude, you might see a single occurrence value at a latitude outside the range of your study. 

You can visualise these plots using the `Relationships` output module. 

**insert here make it like hist freq of colours. ....**

```{r relationships workflow, message = FALSE, warning = FALSE}
#Carolina_Wren_Workflow <- workflow(occurrence = CarolinaWrenPO,
#                                   covariate = CarolinaWrenRasters,
#                                   process = Background(1000),
#                                   model = NullModel,
#                                   output = Relationships)
```

<hr>

# Collinearity

Collinearity is the existence of correlations among covariates. When two covariates in a model are correlated, for example altitude and temperature, then the modelling method will struggle to identify the impact of each variable independently and the significance of either may be masked. If covariate A and covariate B are correlated, for example, one approach would be to include one in the model, preferably based on sound biological justification. Should variable A be included, then in the discussion of the results it will be important to note that the observed effect could equally be driven by correlated covariate B. 

You can check for collinearity in many ways, but the simplest is to look at a pair plot of your covariate data. You can do this in the `PairPlot` output module. Variable names are listed down the diagonal, the bottom half of the panel shows the pairs plots, and the top half shows $r^2$ values for the relationships.

**Saras to make it so pairplot does not have overlapping points - hexbin?**

```{r pairplot workflow, message = FALSE, warning = FALSE}
#Carolina_Wren_Workflow <- workflow(occurrence = CarolinaWrenPO,
#                                   covariate = CarolinaWrenRasters,
#                                   process = Background(1000),
#                                   model = NullModel,
#                                   output = PairPlot)
```

<hr>

A tidy summary of many of the previous data exploration methods is provided by the `GenerateCovariateReport` output module. This is based on the `GenerateReport()` function in the `DataExplorer` `R` package, but tailored specifically for SDM analyses.

This module generates a data profiling report for our training data (the data set that our model is fit to) and/or our raster data (that our model uses to predict the distribution of our study species). These reports will show our data's structure, the percentage of missing data, the distribution of our covariates (histograms for continuous data, bar charts for discrete), and show the results of a correlation analysis. We need to tell the module which report/s to generate by setting the `type` argument to one of `"D"` (Data Report only), `"R"` (Raster report only), or `"DR"` (Data and Raster Report).

<hr>
